<!DOCTYPE html>
<html lang="">
  <head>
    <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="引言"/>







  <link rel="alternate" href="/atom.xml" title="Mr.lin">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.1.0" />



<link rel="canonical" href="http://yoursite.com/2017/01/09/《利用PANDAS进行数据分析》-引言/"/>


<meta name="description" content="准备
请自行安装Pandas与IPython
教程的例子都来自《利用PANDAS进行数据分析》一书~例子用到的数据请到: http://github.com/pydata/pydata-book 下载。
本教程适合有一丢丢编程基础的人
因为本人用了Pandas一段时间，教程里面会掺杂作者的一点心得，并对书中过时的内容进行纠正
默认读这个教程的是略懂python的同学~小白的~请自行补脑~

来自b">
<meta property="og:type" content="article">
<meta property="og:title" content="引言">
<meta property="og:url" content="http://yoursite.com/2017/01/09/《利用PANDAS进行数据分析》-引言/index.html">
<meta property="og:site_name" content="Mr.lin">
<meta property="og:description" content="准备
请自行安装Pandas与IPython
教程的例子都来自《利用PANDAS进行数据分析》一书~例子用到的数据请到: http://github.com/pydata/pydata-book 下载。
本教程适合有一丢丢编程基础的人
因为本人用了Pandas一段时间，教程里面会掺杂作者的一点心得，并对书中过时的内容进行纠正
默认读这个教程的是略懂python的同学~小白的~请自行补脑~

来自b">
<meta property="og:image" content="http://yoursite.com/output_27_3.png">
<meta property="og:image" content="http://yoursite.com/output_45_1.png">
<meta property="og:image" content="http://yoursite.com/output_46_1.png">
<meta property="og:updated_time" content="2017-01-09T12:56:42.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="引言">
<meta name="twitter:description" content="准备
请自行安装Pandas与IPython
教程的例子都来自《利用PANDAS进行数据分析》一书~例子用到的数据请到: http://github.com/pydata/pydata-book 下载。
本教程适合有一丢丢编程基础的人
因为本人用了Pandas一段时间，教程里面会掺杂作者的一点心得，并对书中过时的内容进行纠正
默认读这个教程的是略懂python的同学~小白的~请自行补脑~

来自b">
<meta name="twitter:image" content="http://yoursite.com/output_27_3.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.1.0" />



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />




  



    <title> 引言 · Mr.lin </title>
  </head>

  <body>
    <div class="container">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Mr.lin</a>
</div>

<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            Home
          </a>
        </li>
      
        
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            Archives
          </a>
        </li>
      
      
    </ul>
  
</nav>

<div class="mobile-navbar">
  <div class="mobile-header">
    <div class="mobile-header-logo">
      <a href="/." class="logo">Mr.lin</a>
    </div>

    <div class="mobile-header-icon">
      <span></span>
      <span></span>
      <span></span>
    </div>
  </div>
  <nav class="mobile-menu">
    
      
      <a class="mobile-menu-item" href="/">
        Home
      </a>
    
      
      <a class="mobile-menu-item" href="/archives/">
        Archives
      </a>
    
  </nav>
</div>
      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          引言
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          Jan 9, 2017
        </span>
      </div>
    </header>

    
      <div class="post-toc" id="post-toc">
        <h2 class="post-toc-title">Contents</h2>
        <div class="post-toc-content">
          <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#准备"><span class="toc-text">准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#来自bit-ly的1-usa-gov数据"><span class="toc-text">来自bit.ly的1.usa.gov数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#用纯python对时区进行计数"><span class="toc-text">用纯python对时区进行计数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#利用Pandas对时区进行计数"><span class="toc-text">利用Pandas对时区进行计数</span></a></li></ol>
        </div>
      </div>
    

    <div class="post-content">
      
        <h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ol>
<li>请自行安装Pandas与IPython</li>
<li>教程的例子都来自《利用PANDAS进行数据分析》一书~例子用到的数据请到: <a href="http://github.com/pydata/pydata-book" target="_blank" rel="external">http://github.com/pydata/pydata-book</a> 下载。</li>
<li>本教程适合有一丢丢编程基础的人</li>
<li>因为本人用了Pandas一段时间，教程里面会掺杂作者的一点心得，并对书中过时的内容进行纠正</li>
<li>默认读这个教程的是略懂python的同学~小白的~请自行补脑~</li>
</ol>
<h2 id="来自bit-ly的1-usa-gov数据"><a href="#来自bit-ly的1-usa-gov数据" class="headerlink" title="来自bit.ly的1.usa.gov数据"></a>来自bit.ly的1.usa.gov数据</h2><p>先来看看这里面包含着什么数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">'./pydata-book/ch02/usagov_bitly_data2012-03-16-1331923249.txt'</span></span><br><span class="line">open(path).readline()</span><br></pre></td></tr></table></figure>
<pre><code>&apos;{ &quot;a&quot;: &quot;Mozilla\\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\\/535.11 (KHTML, like Gecko) Chrome\\/17.0.963.78 Safari\\/535.11&quot;, &quot;c&quot;: &quot;US&quot;, &quot;nk&quot;: 1, &quot;tz&quot;: &quot;America\\/New_York&quot;, &quot;gr&quot;: &quot;MA&quot;, &quot;g&quot;: &quot;A6qOVH&quot;, &quot;h&quot;: &quot;wfLQtf&quot;, &quot;l&quot;: &quot;orofrog&quot;, &quot;al&quot;: &quot;en-US,en;q=0.8&quot;, &quot;hh&quot;: &quot;1.usa.gov&quot;, &quot;r&quot;: &quot;http:\\/\\/www.facebook.com\\/l\\/7AQEFzjSi\\/1.usa.gov\\/wfLQtf&quot;, &quot;u&quot;: &quot;http:\\/\\/www.ncbi.nlm.nih.gov\\/pubmed\\/22415991&quot;, &quot;t&quot;: 1331923247, &quot;hc&quot;: 1331822918, &quot;cy&quot;: &quot;Danvers&quot;, &quot;ll&quot;: [ 42.576698, -70.954903 ] }\n&apos;
</code></pre><p>可以看到就是一些json数据，不知道json数据是啥的。。请自行补脑~现在生活中的好多数据都不是直接就弄好给你的~都得你自己提取内容，公司里面在进行网络传输数据的时候，经常用的是json，所以解析json也是常用的方法~python里面就自带着解析json的包：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">records = [json.loads(line) <span class="keyword">for</span> line <span class="keyword">in</span> open(path)]</span><br><span class="line">records[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<pre><code>{u&apos;a&apos;: u&apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.78 Safari/535.11&apos;,
 u&apos;al&apos;: u&apos;en-US,en;q=0.8&apos;,
 u&apos;c&apos;: u&apos;US&apos;,
 u&apos;cy&apos;: u&apos;Danvers&apos;,
 u&apos;g&apos;: u&apos;A6qOVH&apos;,
 u&apos;gr&apos;: u&apos;MA&apos;,
 u&apos;h&apos;: u&apos;wfLQtf&apos;,
 u&apos;hc&apos;: 1331822918,
 u&apos;hh&apos;: u&apos;1.usa.gov&apos;,
 u&apos;l&apos;: u&apos;orofrog&apos;,
 u&apos;ll&apos;: [42.576698, -70.954903],
 u&apos;nk&apos;: 1,
 u&apos;r&apos;: u&apos;http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/wfLQtf&apos;,
 u&apos;t&apos;: 1331923247,
 u&apos;tz&apos;: u&apos;America/New_York&apos;,
 u&apos;u&apos;: u&apos;http://www.ncbi.nlm.nih.gov/pubmed/22415991&apos;}
</code></pre><p>提示点python小知识：</p>
<ul>
<li>python的索引是从0开始的</li>
<li>u’al’等 前面的u代表的是unicode编码 </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">records[<span class="number">0</span>][<span class="string">'tz'</span>]</span><br></pre></td></tr></table></figure>
<pre><code>u&apos;America/New_York&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> records[<span class="number">0</span>][<span class="string">'tz'</span>]</span><br></pre></td></tr></table></figure>
<pre><code>America/New_York
</code></pre><p>上面两个有啥区别？第一个显示的是内容，第二个用了print会更人性化的展示给你看。</p>
<h2 id="用纯python对时区进行计数"><a href="#用纯python对时区进行计数" class="headerlink" title="用纯python对时区进行计数"></a>用纯python对时区进行计数</h2><p>pandas的一个很大的用途就是统计数据，所以下面展示一下如何用pandas对json格式的数据统计：最经常出现的那个时区（即’tz’字段），首先我们先把时区这个数据从record里面提取出来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time_zones = [rec[<span class="string">'tz'</span>] <span class="keyword">for</span> rec <span class="keyword">in</span> records]</span><br></pre></td></tr></table></figure>
<pre><code>---------------------------------------------------------------------------

KeyError                                  Traceback (most recent call last)

&lt;ipython-input-10-db4fbd348da9&gt; in &lt;module&gt;()
----&gt; 1 time_zones = [rec[&apos;tz&apos;] for rec in records]


KeyError: &apos;tz&apos;
</code></pre><p>(⊙o⊙)…居然出错了，因为不是每个record都有时区这个字段啊~稍微修改下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">time_zones = [rec[<span class="string">'tz'</span>] <span class="keyword">for</span> rec <span class="keyword">in</span> records <span class="keyword">if</span> <span class="string">'tz'</span> <span class="keyword">in</span> rec]</span><br><span class="line">time_zones[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>[u&apos;America/New_York&apos;,
 u&apos;America/Denver&apos;,
 u&apos;America/New_York&apos;,
 u&apos;America/Sao_Paulo&apos;,
 u&apos;America/New_York&apos;,
 u&apos;America/New_York&apos;,
 u&apos;Europe/Warsaw&apos;,
 u&apos;&apos;,
 u&apos;&apos;,
 u&apos;&apos;]
</code></pre><p>可以看到,看了前10个数据，就发现空数值了，这个在原始数据里面会经常出现，是个大坑，所以拿到数据之后都需要先进行一波清洗~我们暂时保留这些数据，下面介绍两个方法对出现的时区进行计数：一种用标准的python的标准库，一个用Pandas，大家可以对比下两者的区别：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面两个函数计算每个'tz'出现的次数</span></span><br><span class="line"><span class="comment"># 第一种python函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_counts</span><span class="params">(sequence)</span>:</span></span><br><span class="line">    counts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> sequence:</span><br><span class="line">        <span class="keyword">if</span> x <span class="keyword">in</span> counts:</span><br><span class="line">            counts[x] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            counts[x] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> counts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种python函数，比上面简洁一点</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_counts2</span><span class="params">(sequence)</span>:</span></span><br><span class="line">    counts = defaultdict(int)</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> sequence:</span><br><span class="line">        counts[x] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> counts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将上面获取的time_zones传入</span></span><br><span class="line">counts = get_counts(time_zones)</span><br><span class="line">counts2 = get_counts(time_zones)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">counts[<span class="string">'America/New_York'</span>]</span><br></pre></td></tr></table></figure>
<pre><code>1251
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">counts2[<span class="string">'America/New_York'</span>]</span><br></pre></td></tr></table></figure>
<pre><code>1251
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(time_zones)</span><br></pre></td></tr></table></figure>
<pre><code>3440
</code></pre><p>上面展示了关于一种时区（’America/New_York’）的计数，如果我们想要数量前10的呢，我们还得写个函数，counts里面就存着所有’tz’与其出现计数的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top_counts</span><span class="params">(count_dict, n=<span class="number">10</span>)</span>:</span></span><br><span class="line">    value_key_pairs = [(count,tz) <span class="keyword">for</span> tz,count <span class="keyword">in</span> count_dict.items()]</span><br><span class="line">    value_key_pairs.sort()</span><br><span class="line">    <span class="keyword">return</span> value_key_pairs[-n:]</span><br><span class="line"></span><br><span class="line">top_counts(counts)</span><br></pre></td></tr></table></figure>
<pre><code>[(33, u&apos;America/Sao_Paulo&apos;),
 (35, u&apos;Europe/Madrid&apos;),
 (36, u&apos;Pacific/Honolulu&apos;),
 (37, u&apos;Asia/Tokyo&apos;),
 (74, u&apos;Europe/London&apos;),
 (191, u&apos;America/Denver&apos;),
 (382, u&apos;America/Los_Angeles&apos;),
 (400, u&apos;America/Chicago&apos;),
 (521, u&apos;&apos;),
 (1251, u&apos;America/New_York&apos;)]
</code></pre><p>上面这种Python方法我们需要写两个函数，一个是计算每个时区出现的次数，然后再排序~其实我们可以直接调用python的例外一个类的方法，可以更快的得到我们想要的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">counts = Counter(time_zones)</span><br><span class="line">counts.most_common(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[(u&apos;America/New_York&apos;, 1251),
 (u&apos;&apos;, 521),
 (u&apos;America/Chicago&apos;, 400),
 (u&apos;America/Los_Angeles&apos;, 382),
 (u&apos;America/Denver&apos;, 191),
 (u&apos;Europe/London&apos;, 74),
 (u&apos;Asia/Tokyo&apos;, 37),
 (u&apos;Pacific/Honolulu&apos;, 36),
 (u&apos;Europe/Madrid&apos;, 35),
 (u&apos;America/Sao_Paulo&apos;, 33)]
</code></pre><h2 id="利用Pandas对时区进行计数"><a href="#利用Pandas对时区进行计数" class="headerlink" title="利用Pandas对时区进行计数"></a>利用Pandas对时区进行计数</h2><p>上面用python写是不是觉得挺麻烦的（不过直接用Counter类好像还可以哈~），用pandas就很快了，pandas利用DataFrame作为数据结构来存储多维的表格型的数据（不知道DataFrame是什么东东？没关系~你只要知道pandas是利用这个数据结构存的~而且处理超大数据超快就行了）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame,Series</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">frame = DataFrame(records)</span><br></pre></td></tr></table></figure>
<p>通过DataFrame()函数直接把json数据转化成了表格数据~解析啥的步骤全部省略掉，而且还给你标出了不存在的数据（NaN表示 Not a Number），是不是觉得超级爽看起来~~~~</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frame[<span class="string">'tz'</span>][:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>0     America/New_York
1       America/Denver
2     America/New_York
3    America/Sao_Paulo
4     America/New_York
5     America/New_York
6        Europe/Warsaw
7                     
8                     
9                     
Name: tz, dtype: object
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tz_counts为Pandas里面的Series对象，里面包含着一个计数的方法value_counts()</span></span><br><span class="line">tz_count = frame[<span class="string">'tz'</span>]</span><br><span class="line">tz_count.value_counts()[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>America/New_York       1251
                        521
America/Chicago         400
America/Los_Angeles     382
America/Denver          191
Europe/London            74
Asia/Tokyo               37
Pacific/Honolulu         36
Europe/Madrid            35
America/Sao_Paulo        33
Name: tz, dtype: int64
</code></pre><p>有没有觉得很方便，而且使用Pandas结合IPython，可以很方便的查看每一步的数据，和数据大概的内容，这也是很重要的特性。</p>
<p>然后，我们还可以将我们生成的数据通过matplotlib生成，达成数据清洗，转换，可视一体化步骤。在进行可视化之前我们需要对数据中存在“脏数据”进行一些处理：</p>
<ul>
<li>处理缺失值（NA）</li>
<li>处理空字符串</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fillna这个函数是专门来填充NA值的</span></span><br><span class="line">clean_tz = frame[<span class="string">'tz'</span>].fillna(<span class="string">'Missing'</span>)</span><br><span class="line"><span class="comment"># 再把空字符串处理下</span></span><br><span class="line">clean_tz[clean_tz == <span class="string">''</span>] = <span class="string">'Uknown'</span></span><br><span class="line"></span><br><span class="line">tz_counts = clean_tz.value_counts()</span><br><span class="line">tz_counts[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>America/New_York       1251
Uknown                  521
America/Chicago         400
America/Los_Angeles     382
America/Denver          191
Missing                 120
Europe/London            74
Asia/Tokyo               37
Pacific/Honolulu         36
Europe/Madrid            35
Name: tz, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面这行命令是作者用来在jupyter notebook内显示matplotlib的画图结果的~</span></span><br><span class="line">%pylab inline</span><br><span class="line"><span class="comment"># 直接调用plot方法就可以画图啦</span></span><br><span class="line">tz_counts[:<span class="number">10</span>].plot(kind=<span class="string">'barh'</span>, rot=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Populating the interactive namespace from numpy and matplotlib


/Users/lin/anaconda/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: [&apos;rec&apos;]
`%matplotlib` prevents importing * from pylab and numpy
  &quot;\n`%matplotlib` prevents importing * from pylab and numpy&quot;





&lt;matplotlib.axes._subplots.AxesSubplot at 0x1164690d0&gt;
</code></pre><p><img src="output_27_3.png" alt="png"></p>
<p>除此之外，我们还可以利用Pandas对数据进行更多的处理，例如我们可以看到的是在数据中’a’字段并不止包含了一种信息，还包含着执行URL短缩操作的浏览器，还有程序相关信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frame[<span class="string">'a'</span>][<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<pre><code>u&apos;GoogleMaps/RochesterNY&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frame[<span class="string">'a'</span>][<span class="number">50</span>]</span><br></pre></td></tr></table></figure>
<pre><code>u&apos;Mozilla/5.0 (Windows NT 5.1; rv:10.0.2) Gecko/20100101 Firefox/10.0.2&apos;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frame[<span class="string">'a'</span>][<span class="number">51</span>]</span><br></pre></td></tr></table></figure>
<pre><code>u&apos;Mozilla/5.0 (Linux; U; Android 2.2.2; en-us; LG-P925/V10e Build/FRG83G) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1&apos;
</code></pre><p>要提取这些信息其实是挺蛋疼的事情，这时候我们可以结合python强大的字符串处理能力来解决这个问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果数据是规整的，那么直接可以使用split函数来对数据进行解析</span></span><br><span class="line">results = Series([x.split()[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> frame.a.dropna()])</span><br><span class="line">results[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<pre><code>0               Mozilla/5.0
1    GoogleMaps/RochesterNY
2               Mozilla/4.0
3               Mozilla/5.0
4               Mozilla/5.0
dtype: object
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">results.value_counts()[:<span class="number">8</span>]</span><br></pre></td></tr></table></figure>
<pre><code>Mozilla/5.0                 2594
Mozilla/4.0                  601
GoogleMaps/RochesterNY       121
Opera/9.80                    34
TEST_INTERNET_AGENT           24
GoogleProducer                21
Mozilla/6.0                    5
BlackBerry8520/5.0.0.681       4
dtype: int64
</code></pre><p>现在我们来做一些复杂一些的事情，现在我们想按Windows和非Windows用户对时区统计信息进行分解我们假定只要’a’（agent）字段中包含”Windows”就认为该用户为Windows用户，这时候我们依然要小心的是缺失值，如果事先不把缺失值进行处理，后面处理数据的时候会很坑爹。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 处理NaN</span></span><br><span class="line">cframe = frame[frame.a.notnull()]</span><br><span class="line"><span class="comment"># 根据a值计算出每行是否是Windows</span></span><br><span class="line">operating_system = np.where(cframe[<span class="string">'a'</span>].str.contains(<span class="string">'Windows'</span>), <span class="string">'Windows'</span>, <span class="string">'Not Windows'</span>)</span><br><span class="line"><span class="keyword">print</span> operating_system[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<pre><code>[&apos;Windows&apos; &apos;Not Windows&apos; &apos;Windows&apos; &apos;Not Windows&apos; &apos;Windows&apos;]
</code></pre><p>接下来我们就可以根据时区信息和操作系统信息对数据进行分组了~</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">by_tz_os = cframe.groupby([<span class="string">'tz'</span>, operating_system])</span><br></pre></td></tr></table></figure>
<p>接着我们可以通过size函数对分组结果进行技术（类似于我们上面应用的value_counts函数），并用unstack函数对计数结果进行重塑（显示起来会更好看点，不信大家自己试试不调用unstack函数）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">agg_counts = by_tz_os.size().unstack().fillna(<span class="number">0</span>)</span><br><span class="line">agg_counts[:<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<div><br><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th></th><br>      <th>Not Windows</th><br>      <th>Windows</th><br>    </tr><br>    <tr><br>      <th>tz</th><br>      <th></th><br>      <th></th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th></th><br>      <td>245.0</td><br>      <td>276.0</td><br>    </tr><br>    <tr><br>      <th>Africa/Cairo</th><br>      <td>0.0</td><br>      <td>3.0</td><br>    </tr><br>  </tbody><br></table><br></div>



<p>最后我们来选取最常出现的时区，为了达到这个目的，我们根据agg_counts中的行数构造了一个间接索引数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于按升序排列</span></span><br><span class="line">indexer = agg_counts.sum(<span class="number">1</span>).argsort()</span><br><span class="line">indexer[:<span class="number">10</span>]</span><br></pre></td></tr></table></figure>
<pre><code>tz
                                  24
Africa/Cairo                      20
Africa/Casablanca                 21
Africa/Ceuta                      92
Africa/Johannesburg               87
Africa/Lusaka                     53
America/Anchorage                 54
America/Argentina/Buenos_Aires    57
America/Argentina/Cordoba         26
America/Argentina/Mendoza         55
dtype: int64
</code></pre><p>然后我们通过take函数按照这个顺序截取了最后的10行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">count_subset = agg_counts.take(indexer)[<span class="number">-10</span>:]</span><br><span class="line">count_subset</span><br></pre></td></tr></table></figure>
<div><br><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th></th><br>      <th>Not Windows</th><br>      <th>Windows</th><br>    </tr><br>    <tr><br>      <th>tz</th><br>      <th></th><br>      <th></th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>America/Sao_Paulo</th><br>      <td>13.0</td><br>      <td>20.0</td><br>    </tr><br>    <tr><br>      <th>Europe/Madrid</th><br>      <td>16.0</td><br>      <td>19.0</td><br>    </tr><br>    <tr><br>      <th>Pacific/Honolulu</th><br>      <td>0.0</td><br>      <td>36.0</td><br>    </tr><br>    <tr><br>      <th>Asia/Tokyo</th><br>      <td>2.0</td><br>      <td>35.0</td><br>    </tr><br>    <tr><br>      <th>Europe/London</th><br>      <td>43.0</td><br>      <td>31.0</td><br>    </tr><br>    <tr><br>      <th>America/Denver</th><br>      <td>132.0</td><br>      <td>59.0</td><br>    </tr><br>    <tr><br>      <th>America/Los_Angeles</th><br>      <td>130.0</td><br>      <td>252.0</td><br>    </tr><br>    <tr><br>      <th>America/Chicago</th><br>      <td>115.0</td><br>      <td>285.0</td><br>    </tr><br>    <tr><br>      <th></th><br>      <td>245.0</td><br>      <td>276.0</td><br>    </tr><br>    <tr><br>      <th>America/New_York</th><br>      <td>339.0</td><br>      <td>912.0</td><br>    </tr><br>  </tbody><br></table><br></div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 继续通过matplotlib进行绘图，让我们能深刻的理解数字</span></span><br><span class="line"><span class="comment"># stacked设置为True使得Window与非Windows能组合在一个条形图里面，让我们更清晰的看到数据的对比</span></span><br><span class="line">count_subset.plot(kind = <span class="string">'barh'</span>, stacked=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11e9a4890&gt;
</code></pre><p><img src="output_45_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面的数字太小的了，看不清楚，我们继续将数据进行归一化，让其“总值为1”</span></span><br><span class="line"><span class="comment"># America/New_York  339.0  912.0, 归一化就将： 339/(339+912)</span></span><br><span class="line">normed_subset = count_subset.div(count_subset.sum(<span class="number">1</span>), axis = <span class="number">0</span>)</span><br><span class="line">normed_subset.plot(kind = <span class="string">'barh'</span>, stacked=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11e3bea10&gt;
</code></pre><p><img src="output_46_1.png" alt="png"></p>
<p>不知道这些函数哪里出来的？没事~先了解下Pandas是干啥的，后面每个函数都会讲解的哈~</p>

      
    </div>

    
  </article>


          </div>
          
  <div class="comments" id="comments">
    
  </div>

        </div>  
      </main>

      <footer id="footer" class="footer">
  <div class="social-links">
    
      
        
          <a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    
    
    
  </div>


<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a>
  </span>
  
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2017

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Mr.lin</span>
  </span>
</div>
      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    


    
  





  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

    <script type="text/javascript" src="/js/src/even.js?v=2.1.0"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.1.0"></script>

  </body>
</html>